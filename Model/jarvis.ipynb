{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5b87d9-f8f7-4e3d-a51b-aa70490d9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01f08aa-f36b-4840-82ec-56e3cda62670",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.say(\"Hello rodney\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e18f5e-e164-45d3-89d9-767dd82204a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.say(task)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c8650c-c0fe-4bb4-98aa-eb4a16e26e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening offline with Vosk...\n",
      "\n",
      "Stopped by user.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     24\u001b[0m data \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m2048\u001b[39m, exception_on_overflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAcceptWaveform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     26\u001b[0m     result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(recognizer\u001b[38;5;241m.\u001b[39mResult())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\vosk\\__init__.py:182\u001b[0m, in \u001b[0;36mKaldiRecognizer.AcceptWaveform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAcceptWaveform\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m--> 182\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvosk_recognizer_accept_waveform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m stream\u001b[38;5;241m.\u001b[39mstop_stream()\n\u001b[0;32m     32\u001b[0m stream\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 33\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241m.\u001b[39mterminate()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import pyaudio\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "model = Model(\"C:/Users/Home/Documents/Downloads/vosk-model-en-us-0.22-lgraph/vosk-model-en-us-0.22-lgraph\")\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "mic = pyaudio.PyAudio()\n",
    "stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8192)\n",
    "stream.start_stream()\n",
    "\n",
    "print(\"Listening offline with Vosk...\")\n",
    "\n",
    "#while True:\n",
    "    #data = stream.read(4096, exception_on_overflow=False)\n",
    "    #if recognizer.AcceptWaveform(data):\n",
    "        #result = json.loads(recognizer.Result())\n",
    "        #print(\"You said:\", result['text'])\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stream.read(2048, exception_on_overflow=False)\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            print(\"You said:\", result['text'])\n",
    "        time.sleep(0.01)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416d64b4-7a44-4dad-a176-38532003a782",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create() missing 1 required positional argument: 'access_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DATA_FILE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     21\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mideas\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreminders\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}, f)\n\u001b[1;32m---> 23\u001b[0m porcupine \u001b[38;5;241m=\u001b[39m \u001b[43mpvporcupine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjarvis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m pa \u001b[38;5;241m=\u001b[39m pyaudio\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[0;32m     25\u001b[0m stream \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mopen(\n\u001b[0;32m     26\u001b[0m     rate\u001b[38;5;241m=\u001b[39mporcupine\u001b[38;5;241m.\u001b[39msample_rate,\n\u001b[0;32m     27\u001b[0m     channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     frames_per_buffer\u001b[38;5;241m=\u001b[39mporcupine\u001b[38;5;241m.\u001b[39mframe_length\n\u001b[0;32m     31\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: create() missing 1 required positional argument: 'access_key'"
     ]
    }
   ],
   "source": [
    "import pvporcupine\n",
    "import struct\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pyttsx3\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "model_path = \"C:/Users/Home/Documents/Downloads/vosk-model-en-us-0.22-lgraph/vosk-model-en-us-0.22-lgraph\"\n",
    "model = Model(model_path)\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 160)\n",
    "engine.setProperty('volume', 1.0)\n",
    "\n",
    "DATA_FILE = \"jarvis_data.json\"\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    with open(DATA_FILE, \"w\") as f:\n",
    "        json.dump({\"ideas\": [], \"reminders\": []}, f)\n",
    "        \n",
    "porcupine = pvporcupine.create(keywords=[\"jarvis\"])\n",
    "pa = pyaudio.PyAudio()\n",
    "stream = pa.open(\n",
    "    rate=porcupine.sample_rate,\n",
    "    channels=1,\n",
    "    format=pyaudio.paInt16,\n",
    "    input=True,\n",
    "    frames_per_buffer=porcupine.frame_length\n",
    ")\n",
    "\n",
    "#p = pyaudio.PyAudio()\n",
    "#stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000,\n",
    "                #input=True, frames_per_buffer=2048)\n",
    "#stream.start_stream()\n",
    "\n",
    "def wait_for_wake_word():\n",
    "    speak(\"Say 'Hey Jarvis' when you need me.\")\n",
    "    while True:\n",
    "        pcm = stream.read(porcupine.frame_length, exception_on_overflow=False)\n",
    "        pcm = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "        if porcupine.process(pcm) >= 0:\n",
    "            speak(\"I'm listening...\")\n",
    "            listen_for_command()\n",
    "            speak(\"Anything else? Say 'Hey Jarvis' again if you need me.\")\n",
    "\n",
    "def listen_for_command():\n",
    "    recog = KaldiRecognizer(model, 16000)\n",
    "    local_stream = pa.open(format=pyaudio.paInt16, channels=1, rate=16000,\n",
    "                           input=True, frames_per_buffer=2048)\n",
    "    local_stream.start_stream()\n",
    "    end_time = time.time() + 8  # listen for 8 seconds\n",
    "    while time.time() < end_time:\n",
    "        data = local_stream.read(2048, exception_on_overflow=False)\n",
    "        if recog.AcceptWaveform(data):\n",
    "            result = json.loads(recog.Result())\n",
    "            text = result.get(\"text\", \"\")\n",
    "            if text:\n",
    "                print(\"You said:\", text)\n",
    "                if parse_command(text) == \"exit\":\n",
    "                    local_stream.stop_stream()\n",
    "                    local_stream.close()\n",
    "                    stream.stop_stream()\n",
    "                    porcupine.delete()\n",
    "                    pa.terminate()\n",
    "                    exit()\n",
    "    local_stream.stop_stream()\n",
    "    local_stream.close()\n",
    "\n",
    "def speak(text):\n",
    "    print(\"JARVIS:\", text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def save_data(intent, content):\n",
    "    with open(DATA_FILE, \"r+\") as f:\n",
    "        data = json.load(f)\n",
    "        data[intent].append(content)\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def parse_command(text):\n",
    "    text = text.lower()\n",
    "    if \"idea\" in text:\n",
    "        idea = text.replace(\"add idea\", \"\").strip()\n",
    "        save_data(\"ideas\", idea)\n",
    "        speak(\"Noted your idea. Great thinking!\")\n",
    "    elif \"remind me\" in text:\n",
    "        reminder = text.replace(\"remind me to\", \"\").strip()\n",
    "        save_data(\"reminders\", reminder)\n",
    "        speak(f\"I'll remind you to {reminder}.\")\n",
    "    elif \"stop\" in text or \"exit\" in text:\n",
    "        speak(\"Goodbye, stay productive!\")\n",
    "        return \"exit\"\n",
    "    else:\n",
    "        speak(\"Sorry, I didn't catch a command. Try again?\")\n",
    "    return \"continue\"\n",
    "\n",
    "speak(\"Hello! I'm your assistant. What can I help you with today?\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stream.read(2048, exception_on_overflow=False)\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            text = result.get(\"text\", \"\")\n",
    "            if text:\n",
    "                print(\"You said:\", text)\n",
    "                status = parse_command(text)\n",
    "                if status == \"exit\":\n",
    "                    break\n",
    "                speak(\"Anything else you'd like to add?\")\n",
    "except KeyboardInterrupt:\n",
    "    speak(\"Session ended. Goodbye.\")\n",
    "finally:\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd66edbe-c347-4db1-a048-5022886e9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JARVIS: Say 'Hey Jarvis' when you need me.\n",
      "JARVIS: I'm listening...\n",
      "JARVIS: Anything else? Just say 'Hey Jarvis'.\n",
      "JARVIS: I'm listening...\n",
      "You said: but\n",
      "JARVIS: I didn't catch that. Could you repeat it?\n",
      "JARVIS: Anything else? Just say 'Hey Jarvis'.\n",
      "JARVIS: I'm listening...\n",
      "You said: stop\n",
      "JARVIS: Goodbye. Stay productive!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import struct\n",
    "import pyttsx3\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import pvporcupine\n",
    "\n",
    "# === SETUP ===\n",
    "# Load Vosk model\n",
    "VOSK_MODEL_PATH = \"C:/Users/Home/Documents/Downloads/vosk-model-en-us-0.22-lgraph/vosk-model-en-us-0.22-lgraph\"\n",
    "model = Model(VOSK_MODEL_PATH)\n",
    "\n",
    "# Setup TTS\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 160)\n",
    "engine.setProperty('volume', 1.0)\n",
    "\n",
    "# Wake word setup\n",
    "key = os.getenv(\"ACCESS_KEY\")\n",
    "porcupine = pvporcupine.create(key, keywords=[\"jarvis\"])\n",
    "\n",
    "pa = pyaudio.PyAudio()\n",
    "wake_stream = pa.open(\n",
    "    rate=porcupine.sample_rate,\n",
    "    channels=1,\n",
    "    format=pyaudio.paInt16,\n",
    "    input=True,\n",
    "    frames_per_buffer=porcupine.frame_length\n",
    ")\n",
    "\n",
    "# Data file\n",
    "DATA_FILE = \"jarvis_data.json\"\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    with open(DATA_FILE, \"w\") as f:\n",
    "        json.dump({\"ideas\": [], \"reminders\": []}, f)\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "def speak(text):\n",
    "    print(\"JARVIS:\", text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def save_data(intent, content):\n",
    "    with open(DATA_FILE, \"r+\") as f:\n",
    "        data = json.load(f)\n",
    "        data[intent].append(content)\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def parse_command(text):\n",
    "    text = text.lower()\n",
    "    if \"idea\" in text:\n",
    "        idea = text.replace(\"add idea\", \"\").strip()\n",
    "        save_data(\"ideas\", idea)\n",
    "        speak(\"Great idea. I've noted that.\")\n",
    "    elif \"remind me\" in text:\n",
    "        reminder = text.replace(\"remind me to\", \"\").strip()\n",
    "        save_data(\"reminders\", reminder)\n",
    "        speak(f\"Okay, I will remind you to {reminder}.\")\n",
    "    elif \"exit\" in text or \"stop\" in text:\n",
    "        speak(\"Goodbye. Stay productive!\")\n",
    "        return \"exit\"\n",
    "    else:\n",
    "        speak(\"I didn't catch that. Could you repeat it?\")\n",
    "    return \"continue\"\n",
    "\n",
    "def listen_for_command():\n",
    "    recog = KaldiRecognizer(model, 16000)\n",
    "    stream = pa.open(format=pyaudio.paInt16, channels=1, rate=16000,\n",
    "                     input=True, frames_per_buffer=2048)\n",
    "    stream.start_stream()\n",
    "\n",
    "    speak(\"I'm listening...\")\n",
    "    end_time = time.time() + 8  # listen for 8 seconds\n",
    "\n",
    "    while time.time() < end_time:\n",
    "        data = stream.read(2048, exception_on_overflow=False)\n",
    "        if recog.AcceptWaveform(data):\n",
    "            result = json.loads(recog.Result())\n",
    "            text = result.get(\"text\", \"\")\n",
    "            if text:\n",
    "                print(\"You said:\", text)\n",
    "                if parse_command(text) == \"exit\":\n",
    "                    stream.stop_stream()\n",
    "                    stream.close()\n",
    "                    return \"exit\"\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "def wait_for_wake_word():\n",
    "    speak(\"Say 'Hey Jarvis' when you need me.\")\n",
    "    while True:\n",
    "        pcm = wake_stream.read(porcupine.frame_length, exception_on_overflow=False)\n",
    "        pcm = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "        if porcupine.process(pcm) >= 0:\n",
    "            result = listen_for_command()\n",
    "            if result == \"exit\":\n",
    "                break\n",
    "            speak(\"Anything else? Just say 'Hey Jarvis'.\")\n",
    "\n",
    "# === START ===\n",
    "try:\n",
    "    wait_for_wake_word()\n",
    "except KeyboardInterrupt:\n",
    "    speak(\"Session ended. Goodbye.\")\n",
    "finally:\n",
    "    wake_stream.stop_stream()\n",
    "    wake_stream.close()\n",
    "    porcupine.delete()\n",
    "    pa.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5867cd8-23bc-4018-9a0f-7220ed2b7ec1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model \"llama3\" not found, try pulling it first (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello Jarvis, who are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:342\u001b[0m, in \u001b[0;36mClient.chat\u001b[1;34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[0;32m    298\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    299\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[0;32m    309\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:180\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[0;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:124\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 124\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n\u001b[0;32m    126\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mResponseError\u001b[0m: model \"llama3\" not found, try pulling it first (status code: 404)"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello Jarvis, who are you?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5800c-f02a-4be2-b8d2-72932410601d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
